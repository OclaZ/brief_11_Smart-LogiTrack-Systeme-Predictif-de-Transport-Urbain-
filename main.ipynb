{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b01c6f",
   "metadata": {},
   "source": [
    "### initialisation de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f31ffd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder .appName(\"TransportProject\") .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516ecc1",
   "metadata": {},
   "source": [
    "### load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c895765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       1| 2025-01-01 00:18:38|  2025-01-01 00:26:59|              1|          1.6|         1|                 N|         229|         237|           1|       10.0|  3.5|    0.5|       3.0|         0.0|                  1.0|        18.0|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-01-01 00:32:40|  2025-01-01 00:35:13|              1|          0.5|         1|                 N|         236|         237|           1|        5.1|  3.5|    0.5|      2.02|         0.0|                  1.0|       12.12|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-01-01 00:44:04|  2025-01-01 00:46:01|              1|          0.6|         1|                 N|         141|         141|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|               0.0|\n",
      "|       2| 2025-01-01 00:14:27|  2025-01-01 00:20:01|              3|         0.52|         1|                 N|         244|         244|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|         9.7|                 0.0|        0.0|               0.0|\n",
      "|       2| 2025-01-01 00:21:34|  2025-01-01 00:25:06|              3|         0.66|         1|                 N|         244|         116|           2|        5.8|  1.0|    0.5|       0.0|         0.0|                  1.0|         8.3|                 0.0|        0.0|               0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "Nombre de lignes (Bronze) : 3475226\n"
     ]
    }
   ],
   "source": [
    "df_bronze=spark.read.parquet('data/bronze/dataset.parquet')\n",
    "df_bronze.show(5)\n",
    "print(f\"Nombre de lignes (Bronze) : {df_bronze.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c5f9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|0       |0                   |0                    |540149         |0            |540149    |540149            |0           |0           |0           |0          |0    |0      |0         |0           |0                    |0           |540149              |540149     |0                 |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count,isnan\n",
    "from pyspark.sql.types import DoubleType, FloatType\n",
    "\n",
    "def check_missing_values(df):\n",
    "    exprs = []\n",
    "    \n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dtype = field.dataType\n",
    "        \n",
    "        # Numeric columns â†’ check NULL or NaN\n",
    "        if isinstance(dtype, (DoubleType, FloatType)):\n",
    "            exprs.append(\n",
    "                count(\n",
    "                    when(col(c).isNull() | isnan(col(c)), c)\n",
    "                ).alias(c)\n",
    "            )\n",
    "        # Other types â†’ only NULL\n",
    "        else:\n",
    "            exprs.append(\n",
    "                count(\n",
    "                    when(col(c).isNull(), c)\n",
    "                ).alias(c)\n",
    "            )\n",
    "\n",
    "    df.select(exprs).show(truncate=False)\n",
    "\n",
    "check_missing_values(df_bronze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09b901",
   "metadata": {},
   "source": [
    "### handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "554487a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp, hour, dayofweek, month, round\n",
    "from pyspark.sql.types import (DoubleType, FloatType, IntegerType, LongType, StringType)\n",
    "\n",
    "def handle_missing_values(df):\n",
    "\n",
    "    # 1ï¸âƒ£ NUMERIC columns (Double / Float only â†’ mean)\n",
    "    numeric_cols = [\n",
    "        field.name for field in df.schema.fields\n",
    "        if isinstance(field.dataType, (DoubleType, FloatType))\n",
    "    ]\n",
    "\n",
    "    for col_name in numeric_cols:\n",
    "        mean_value = (\n",
    "            df.select(col_name)\n",
    "              .where(col(col_name).isNotNull())\n",
    "              .groupBy()\n",
    "              .mean()\n",
    "              .first()[0]\n",
    "        )\n",
    "\n",
    "        if mean_value is not None:\n",
    "            df = df.na.fill({col_name: mean_value})\n",
    "\n",
    "    # 2ï¸âƒ£ INTEGER columns (IDs, counts) â†’ fill with -1 or 0\n",
    "    int_cols = [\n",
    "        field.name for field in df.schema.fields\n",
    "        if isinstance(field.dataType, (IntegerType, LongType))\n",
    "    ]\n",
    "\n",
    "    for col_name in int_cols:\n",
    "        df = df.na.fill({col_name: -1})\n",
    "\n",
    "    # 3ï¸âƒ£ STRING columns ONLY â†’ fill with \"Unknown\"\n",
    "    string_cols = [\n",
    "        field.name for field in df.schema.fields\n",
    "        if isinstance(field.dataType, StringType)\n",
    "    ]\n",
    "\n",
    "    for col_name in string_cols:\n",
    "        df = df.na.fill({col_name: \"Unknown\"})\n",
    "\n",
    "    # 4ï¸âƒ£ DO NOTHING for TIMESTAMP columns (very important)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_cleaned = handle_missing_values(df_bronze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea85dc9",
   "metadata": {},
   "source": [
    "### handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bd0d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_duplicates(df):\n",
    "    return df.dropDuplicates()\n",
    "\n",
    "df_no_duplicates = handle_duplicates(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c813db",
   "metadata": {},
   "source": [
    "### Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0138bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+----------------+----------+----------+-----+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|duration_minutes|pickuphour|dayof_week|month|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+----------------+----------+----------+-----+\n",
      "|       2| 2025-01-01 00:40:52|  2025-01-01 00:44:10|              1|         0.55|         1|                 N|         237|         237|           1|        5.8|  1.0|    0.5|      2.16|         0.0|                  1.0|       12.96|                 2.5|        0.0|               0.0|             3.3|         0|         4|    1|\n",
      "|       2| 2025-01-01 00:49:54|  2025-01-01 01:05:46|              1|         3.01|         1|                 N|         148|          13|           1|       18.4|  1.0|    0.5|      4.68|         0.0|                  1.0|       28.08|                 2.5|        0.0|               0.0|           15.87|         0|         4|    1|\n",
      "|       2| 2025-01-01 00:28:00|  2025-01-01 00:34:08|              1|         1.41|         1|                 N|         141|         263|           1|        8.6|  1.0|    0.5|      2.72|         0.0|                  1.0|       16.32|                 2.5|        0.0|               0.0|            6.13|         0|         4|    1|\n",
      "|       2| 2025-01-01 00:25:46|  2025-01-01 00:37:45|              1|         1.74|         1|                 N|         113|          68|           1|       12.1|  1.0|    0.5|      3.42|         0.0|                  1.0|       20.52|                 2.5|        0.0|               0.0|           11.98|         0|         4|    1|\n",
      "|       2| 2025-01-01 00:46:53|  2025-01-01 00:54:46|              3|         1.12|         1|                 N|         209|         148|           1|        9.3|  1.0|    0.5|       0.0|         0.0|                  1.0|        14.3|                 2.5|        0.0|               0.0|            7.88|         0|         4|    1|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+----------------+----------+----------+-----+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- VendorID: integer (nullable = false)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = false)\n",
      " |-- trip_distance: double (nullable = false)\n",
      " |-- RatecodeID: long (nullable = false)\n",
      " |-- store_and_fwd_flag: string (nullable = false)\n",
      " |-- PULocationID: integer (nullable = false)\n",
      " |-- DOLocationID: integer (nullable = false)\n",
      " |-- payment_type: long (nullable = false)\n",
      " |-- fare_amount: double (nullable = false)\n",
      " |-- extra: double (nullable = false)\n",
      " |-- mta_tax: double (nullable = false)\n",
      " |-- tip_amount: double (nullable = false)\n",
      " |-- tolls_amount: double (nullable = false)\n",
      " |-- improvement_surcharge: double (nullable = false)\n",
      " |-- total_amount: double (nullable = false)\n",
      " |-- congestion_surcharge: double (nullable = false)\n",
      " |-- Airport_fee: double (nullable = false)\n",
      " |-- cbd_congestion_fee: double (nullable = false)\n",
      " |-- duration_minutes: double (nullable = true)\n",
      " |-- pickuphour: integer (nullable = true)\n",
      " |-- dayof_week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, unix_timestamp, hour, dayofweek, month, round\n",
    ")\n",
    "\n",
    "# ðŸ”¹ SÃ©curitÃ© : supprimer les colonnes si elles existent dÃ©jÃ \n",
    "cols_to_drop = [\"duration_minutes\", \"pickuphour\", \"dayof_week\", \"month\"]\n",
    "df_silver = df_no_duplicates.drop(*[c for c in cols_to_drop if c in df_no_duplicates.columns])\n",
    "\n",
    "# 1ï¸âƒ£ Calcul de la durÃ©e en minutes\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"duration_minutes\",\n",
    "    round(\n",
    "        (unix_timestamp(\"tpep_dropoff_datetime\") -\n",
    "         unix_timestamp(\"tpep_pickup_datetime\")) / 60,\n",
    "        2\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ Filtrage des trajets aberrants\n",
    "df_silver = df_silver.filter(\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"trip_distance\") <= 200) &\n",
    "    (col(\"duration_minutes\") > 0) &\n",
    "    (col(\"passenger_count\") > 0)\n",
    ")\n",
    "\n",
    "# 3ï¸âƒ£ Features temporelles\n",
    "df_silver = (\n",
    "    df_silver\n",
    "    .withColumn(\"pickuphour\", hour(\"tpep_pickup_datetime\"))\n",
    "    .withColumn(\"dayof_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "    .withColumn(\"month\", month(\"tpep_pickup_datetime\"))\n",
    ")\n",
    "\n",
    "# 4ï¸âƒ£ VÃ©rification\n",
    "df_silver.show(5)\n",
    "df_silver.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6d672d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 158:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+--------------------+\n",
      "|summary|     trip_distance|  duration_minutes|   passenger_count|        pickuphour|        dayof_week|               month|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+--------------------+\n",
      "|  count|           2871275|           2871275|           2871275|           2871275|           2871275|             2871275|\n",
      "|   mean|3.1930232631845143|15.111674618418885|1.3080283149471925|14.387960749144543| 4.247460448755344|  1.0000808003413117|\n",
      "| stddev| 4.359738082143162|29.095096636594906|0.7430467194763688| 5.534282505920479|1.8933577854610746|0.029754239374199302|\n",
      "|    min|              0.01|              0.02|                 1|                 0|                 1|                   1|\n",
      "|    25%|              0.99|              7.05|                 1|                11|                 3|                   1|\n",
      "|    50%|              1.63|             11.35|                 1|                15|                 4|                   1|\n",
      "|    75%|              3.01|             18.15|                 1|                19|                 6|                   1|\n",
      "|    max|             199.3|           5626.32|                 9|                23|                 7|                  12|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_silver.select(\n",
    "    \"trip_distance\",\n",
    "    \"duration_minutes\",\n",
    "    \"passenger_count\",\n",
    "    \"pickuphour\",\n",
    "    \"dayof_week\",\n",
    "    \"month\"\n",
    ").summary().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743bd5d",
   "metadata": {},
   "source": [
    "### Stockage Silver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c8b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/07 10:11:26 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df_silver.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"data/silver\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
